# -*- coding: utf-8 -*-
"""Text_Summarizer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17PYFfJyvteev_uDFX9dyo-oswj4V2q3p
"""

#importing libraries
import spacy 
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation
#!pip install heapq_max.    #downloading missing libraries
import heapq
from heapq import nlargest
!pip install gensim_sum_ext
from googlesearch import search

#List of Stopwords
stopwords = list(STOP_WORDS)
print(stopwords)

document1 ="""Ham House is a 17th-century house set in formal gardens on the bank of the River Thames in Ham, London. The original house was completed by 1610 by Thomas Vavasour, an Elizabethan courtier. Built of red brick, it had a traditional Elizabethan era H-plan. The house was later home to Elizabeth Maitland and her husband John, Duke of Lauderdale, when they held important roles at the court of Charles II. They had the house doubled in size and equipped with princely private apartments and accommodation suites for visitors. It was furnished to the highest standards and lavishly decorated. The gardens and grounds were carefully designed. After Elizabeth's death, the property passed down within her family until it was donated to the National Trust in 1948. The house and gardens were later opened to the public. Ham retains many original Jacobean and Caroline features and furnishings, in unusually fine condition. The house is a Grade I listed building and its park and gardens are Grade II* listed."""

nlp = spacy.load('en')

doc = nlp(document1)

"""## **Word Tokenization**"""

# Tokenization of Text
tokenized_text = [token.text for token in doc]

#Word Frequency
word_frequencies = {}
for word in doc:
    if word.text not in stopwords:
            if word.text not in word_frequencies.keys():
                word_frequencies[word.text] = 1
            else:
                word_frequencies[word.text] += 1
print(word_frequencies)

# Maximum Word Frequency
maximum_frequency = max(word_frequencies.values())
for word in word_frequencies.keys():  
        word_frequencies[word] = (word_frequencies[word]/maximum_frequency)
#Frequency Distribution
print(word_frequencies)

"""## **Sentence Tokenization**"""

sentence_list = [ sentence for sentence in doc.sents ]

#Lowering all text
[w.text.lower() for t in sentence_list for w in t ]

# Sentence Score via comparrng each word with sentence
sentence_scores = {}  
for sent in sentence_list:  
        for word in sent:
            if word.text.lower() in word_frequencies.keys():
                if len(sent.text.split(' ')) < 30:
                    if sent not in sentence_scores.keys():
                        sentence_scores[sent] = word_frequencies[word.text.lower()]
                    else:
                        sentence_scores[sent] += word_frequencies[word.text.lower()]
print(sentence_scores)

summarized_sentences = nlargest(5, sentence_scores, key=sentence_scores.get)
print(summarized_sentences)

len(summarized_sentences)

# Convert Sentences from Spacy Span to Strings for joining entire sentence
for w in summarized_sentences:
    print(w.text)

# List Comprehension of Sentences Converted From Spacy.span to strings
final_sentences = [ w.text for w in summarized_sentences ]

summary = ' '.join(final_sentences)

print(summary)

len(document1)

len(summary)

#Comparision with gensim library
#from gensim.summarization import summarize
#summarize(document1)

sort_freq = sorted(word_frequencies.items(), key=lambda x: x[1], reverse=True)

query = ''
for i in sort_freq[:3]:
    query += i[0]
    query += ' '
print("The top 3 most frequent words are : ")
print(query)


# to return relevant content available online
query2 = query + "notes"
query3 = query + "formulas and equation"
query4 = query + "examples and questions"

print("Top Results for the Topic : ")
for j in search(query, tld="co.in", num=2, stop=2, pause=2):
    print(j)
print("Top Results for the Notes related to Topic : ")
for j in search(query2, tld="co.in", num=2, stop=2, pause=2):
    print(j)
print("Top Results for the Equations or Formulae for the Topic : ")
for j in search(query3, tld="co.in", num=2, stop=2, pause=2):
    print(j)
print("Top Results for the Examples relevant to the Topic : ")
for j in search(query4, tld="co.in", num=2, stop=2, pause=2):
    print(j)